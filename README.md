# genai-raga-langgraph

GenAI RAGA system built with LangGraph, FastAPI, and vector databasesâ€”combining Retrievalâ€‘Augmented Generation with actionable, multiâ€‘step AI workflows

**Author:** Aniket Waichal

---

# GenAI RAGA System (RAG + Actions)

ğŸš€ **GenAI RAGA System** is a productionâ€‘ready AI architecture that demonstrates the **evolution of modern GenAI systems** â€” from **classic RAG**, to **RAGA (RAG + Actions)**, and into **early Agentic AI workflows**.

Before diving into RAGA and Agentic concepts, it is important to understand the foundation: **Retrievalâ€‘Augmented Generation (RAG)**.

---

## ğŸ§© What is RAG? (Foundation)

**Retrievalâ€‘Augmented Generation (RAG)** is a technique that enhances Large Language Models by grounding responses in external knowledge sources.

In a standard RAG system:

* User queries are embedded and searched against a **vector database**
* Relevant documents are retrieved
* Retrieved context is injected into the LLM prompt
* The LLM generates a grounded response

**Why RAG matters:**

* Reduces hallucinations
* Enables domainâ€‘specific knowledge
* Keeps models stateless while data stays external

This project includes a **pure RAG pipeline** as a baseline, which then evolves into RAGA and Agentic systems.

---

## ğŸ” What is RAGA?

**RAGA (Retrievalâ€‘Augmented Generation + Actions)** goes beyond answering questions.

It allows AI systems to:

* Retrieve relevant knowledge from vector databases (RAG)
* Reason over retrieved results using LLMs
* Perform **actions** such as routing, validation, summarization, tool usage, and multiâ€‘step orchestration

This project uses **LangGraph** to orchestrate these steps as an explicit graph of nodes, making the system interpretable, debuggable, and extensible.

---

## âœ¨ Key Features

* âœ… Agentic AI foundations (planner, decision routing, stateful graphs)

* âœ… Retrievalâ€‘Augmented Generation (RAG)

* âœ… LangGraphâ€‘based workflow orchestration

* âœ… RAGA architecture (RAG â†’ Reason â†’ Action â†’ Validate)

* âœ… Action nodes (decision, tool, summarization, validation)

* âœ… Multiâ€‘LLM support (Ollamaâ€‘first, extensible to OpenAI/Azure)

* âœ… FastAPI backend for API access

* âœ… Modular, productionâ€‘ready code structure

* âœ… Designed for Agentic AI and workflowâ€‘driven systems

---

## ğŸ—ï¸ Architecture Overview

This project intentionally exposes **RAG, RAGA, and Agentic systems as separate API flows** via FastAPI. This separation highlights architectural evolution and keeps each system independently testable and extensible.

**Highâ€‘level Flow**

Client / User
â†“
FastAPI API Layer
â†“
LangGraph Workflow Engine
â†“
RAGA Workflow Nodes

---

### ğŸ§  RAGA & Agentic Workflow (LangGraph)

This system is **not a single-pass RAG pipeline**. It is an **early Agentic AI architecture** where decisions, actions, and state transitions are explicitly modeled.

1. **Planner / Decision Node**

   * Interprets user intent
   * Decides next steps in the workflow

2. **RAG Node**

   * Retrieves relevant documents from vector store
   * Generates grounded answers using LLM + context

3. **Action Nodes**

   * Tool execution
   * Postâ€‘processing
   * Query refinement
   * Summarization

4. **Validation Node**

   * Checks grounding against retrieved context
   * Calculates confidence / overlap metrics

5. **Agentic Control Loop**

   * Shared `AgentState` passed across nodes
   * Planner & decision nodes choose next actions dynamically
   * Enables future multi-agent or looping behaviors

6. **Final Response Node**

   * Returns structured output to API client

---

### ğŸ” Flow Explanation

The FastAPI layer exposes **three distinct systems**:

1. **RAG API** â€“ Classic retrieval + generation

2. **RAGA API** â€“ RAG extended with actions

3. **Agentic API** â€“ Decisionâ€‘driven, stateful workflows

4. User sends a query via REST API

5. FastAPI triggers the LangGraph execution

6. Planner node decides the workflow path

7. RAG node retrieves documents and generates an answer

8. Optional action nodes refine, validate, or summarize

9. Final structured response is returned to the client

---

## ğŸ“ Project Structure

The structure below reflects the **actual repository layout**, exactly as implemented, showing clear separation between **RAG**, **RAGA**, and **Agentic workflows**:

```
genai-raga-langgraph/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ actions/
â”‚   â”‚   â”œâ”€â”€ base_action.py        # Base class for actions
â”‚   â”‚   â””â”€â”€ example_action.py     # Sample action implementation
â”‚   â”‚
â”‚   â”œâ”€â”€ agent/
â”‚   â”‚   â”œâ”€â”€ agentic_raga_graph.py # Agentic RAGA LangGraph
â”‚   â”‚   â”œâ”€â”€ critic.py             # Critic / evaluation logic
â”‚   â”‚   â”œâ”€â”€ document.py           # Agent document abstraction
â”‚   â”‚   â”œâ”€â”€ executor.py           # Agent execution controller
â”‚   â”‚   â”œâ”€â”€ graph.py              # Core LangGraph wiring
â”‚   â”‚   â”œâ”€â”€ nodes.py              # Shared agent nodes
â”‚   â”‚   â”œâ”€â”€ planner.py            # Planner / decision logic
â”‚   â”‚   â””â”€â”€ state.py              # Agent state definition
â”‚   â”‚
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â””â”€â”€ routes.py             # FastAPI route definitions
â”‚   â”‚
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â””â”€â”€ settings.py           # Application & LLM settings
â”‚   â”‚
â”‚   â”œâ”€â”€ llm/
â”‚   â”‚   â”œâ”€â”€ base.py               # Base LLM interface
â”‚   â”‚   â”œâ”€â”€ factory.py            # LLM factory
â”‚   â”‚   â””â”€â”€ ollama_client.py      # Ollama client
â”‚   â”‚
â”‚   â”œâ”€â”€ nodes/
â”‚   â”‚   â”œâ”€â”€ action_node.py        # Action execution node
â”‚   â”‚   â”œâ”€â”€ decision_node.py      # Decision / routing node
â”‚   â”‚   â”œâ”€â”€ raga_node.py          # RAGA node
â”‚   â”‚   â”œâ”€â”€ summarize_node.py     # Summarization node
â”‚   â”‚   â””â”€â”€ tool_node.py          # Tool execution node
â”‚   â”‚
â”‚   â”œâ”€â”€ rag_system/
â”‚   â”‚   â”œâ”€â”€ ingestion.py          # Document ingestion
â”‚   â”‚   â”œâ”€â”€ llm_clients.py        # RAG-specific LLM clients
â”‚   â”‚   â”œâ”€â”€ load_processed.py     # Load processed vectors
â”‚   â”‚   â”œâ”€â”€ rag_pipeline.py       # Classic RAG pipeline
â”‚   â”‚   â”œâ”€â”€ rag_service.py        # RAG service layer
â”‚   â”‚   â””â”€â”€ vector_store.py       # Vector database logic
â”‚   â”‚
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â””â”€â”€ ollama.py             # Ollama health checks
â”‚   â”‚
â”‚   â””â”€â”€ workflows/
â”‚       â”œâ”€â”€ raga_graph.py         # RAGA workflow graph
â”‚       â””â”€â”€ state_schema.py       # Workflow state schema
â”‚
â”œâ”€â”€ data/                          # Documents / datasets
â”œâ”€â”€ scripts/                       # Utility scripts
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_raga.py
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ main.py                        # FastAPI entry point
â”œâ”€â”€ LICENSE
â””â”€â”€ README.md
```

---

## âš™ï¸ Tech Stack

* **Python**
* **FastAPI**
* **LangGraph**
* **LangChain**
* **FAISS / Vector Databases**
* **Ollama (local LLMs)**
* *(Extensible to OpenAI / Azure OpenAI)*

---

## ğŸš€ Installation & Setup

### 1. Clone Repository

```bash
git clone https://github.com/<your-username>/genai-raga-langgraph.git
cd genai-raga-langgraph
```

### 2. Create Virtual Environment

```bash
python -m venv venv
source venv/bin/activate      # Windows: venv\Scripts\activate
```

### 3. Install Dependencies

```bash
pip install -r requirements.txt
```

---

## ğŸ¦™ Ollama Server (Required)

Start Ollama:

```bash
ollama serve
```

Verify:

```bash
curl http://127.0.0.1:11434
```

Ensure the required model is pulled:

```bash
#RAG and RAGA
ollama pull llama3
# Planner
ollama pull qwen2.5:7b-instruct
# Executor / Answer generation
ollama pull qwen2.5:14b-instruct
# Validator / reasoning
ollama pull qwen2.5:3b-instruct

```

---

## â–¶ï¸ Running the Application

```bash
uvicorn app.main:app --reload
```

Server runs at:

```
http://127.0.0.1:8000
```

---

## ğŸ¯ Project Goal

This project intentionally goes beyond classic RAG and introduces **Agentic AI concepts** such as:

* Explicit planning and decision nodes
* Stateful graph-based execution
* Action selection instead of fixed pipelines

It demonstrates how RAG systems evolve into **agentic, reasoning-driven architectures**.

This project is designed to:

* Demonstrate **RAGA (RAG + Actions)** in practice
* Showcase **LangGraphâ€‘based orchestration**
* Serve as a strong **portfolioâ€‘grade GenAI system**
* Act as a foundation for **Agentic AI workflows**

---

## ğŸ”® Future Enhancements

* Fully autonomous agent loops

* Multi-agent coordination

* Tool planning & execution graphs

* Long-term memory & reflection

* Hybrid search (BM25 + Vector)

* Production observability & tracing

* Multiâ€‘agent collaboration

* Toolâ€‘calling via function schemas

* Memory & longâ€‘term state

* Hybrid search (BM25 + Vector)

* Production observability & tracing

---

â­ If you find this project useful, consider starring the repository.
